{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter nbconvert --to python 04_submit.ipynb\n",
    "# 在命令行下将本文件转为python文件 挂在tmux下运行 网络不稳定 在notebook内训练会丢失结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import cv2\n",
    "import glob\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "from albumentations import Compose, ShiftScaleRotate, Resize\n",
    "import albumentations as alb\n",
    "from albumentations.pytorch import ToTensor\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import pretrainedmodels\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_csv = dir_dcm = '/home/jupyter/rsna/source_data'\n",
    "dir_train_img = '/home/jupyter/rsna/rsna-train-stage-1-images-png-224x/stage_1_train_png_224x'\n",
    "dir_test_img = '/home/jupyter/rsna/rsna-train-stage-1-images-png-224x/stage_1_test_png_224x'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved = 'saved'\n",
    "train = pd.read_csv(f'{saved}/train.csv')\n",
    "test = pd.read_csv(f'{saved}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntracranialDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, path, labels, transform=None):\n",
    "        \n",
    "        self.path = path\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_name = os.path.join(self.path, self.data.loc[idx, 'Image'] + '.png')\n",
    "        img = cv2.imread(img_name)   \n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img)\n",
    "            img = augmented['image']   \n",
    "            \n",
    "        if self.labels:\n",
    "            \n",
    "            labels = torch.tensor(\n",
    "                self.data.loc[idx, ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']])\n",
    "            return {'image': img, 'labels': labels}    \n",
    "        \n",
    "        else:      \n",
    "            return {'image': img}\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 6\n",
    "n_epochs = 100\n",
    "\n",
    "\n",
    "n_classes = 6\n",
    "n_epochs = 100\n",
    "\n",
    "batch_size = 6*7 # se_resnext50_32x4d 224*224\n",
    "\n",
    "batch_size = 6*7*3 * 2 # se_resnext50_32x4d 128*128\n",
    "\n",
    "batch_size = 6*7*2*7 # 16GB se_resnext50_32x4d 128*128  fp16\n",
    "resize_size = (128, 128)\n",
    "\n",
    "batch_size = 6*7*2*4 # 16GB se_resnext50_32x4d 164*164  fp16\n",
    "resize_size = (164, 164)\n",
    "\n",
    "batch_size = int(1.4*6*7*1*3) # 16GB se_resnext50_32x4d 164*164  fp16\n",
    "resize_size = (224, 224)\n",
    "\n",
    "val_batch_size = batch_size * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "\n",
    "transform_train = Compose([\n",
    "    alb.HorizontalFlip(),\n",
    "    alb.VerticalFlip(),\n",
    "    alb.RandomRotate90(),\n",
    "    alb.GridDistortion(),\n",
    "    ShiftScaleRotate(),\n",
    "    alb.Resize(*resize_size),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "transform_test= Compose([\n",
    "#     alb.Resize(512, 512),\n",
    "    alb.Resize(*resize_size),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "test_dataset = IntracranialDataset(\n",
    "    csv_file=f'{saved}/test.csv', path=dir_test_img, transform=transform_test, labels=False)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(test_dataset, batch_size=val_batch_size, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# http://stackoverflow.com/questions/34950201/pycharm-print-end-r-statement-not-working\n",
    "class Logger(object):\n",
    "    def __init__(self):\n",
    "        self.terminal = sys.stdout  #stdout\n",
    "        self.file = None\n",
    "\n",
    "    def open(self, file, mode=None):\n",
    "        if mode is None: mode ='a+'\n",
    "        self.file = open(file, mode)\n",
    "        self.file.write('\\n----\\n')\n",
    "\n",
    "    def write(self, message, is_terminal=1, is_file=1 ):\n",
    "        if '\\r' in message: is_file=0\n",
    "\n",
    "        if is_terminal == 1:\n",
    "            self.terminal.write(message)\n",
    "            self.terminal.flush()\n",
    "            #time.sleep(1)\n",
    "\n",
    "        if is_file == 1:\n",
    "            self.file.write(message)\n",
    "            self.file.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        # this flush method is needed for python 3 compatibility.\n",
    "        # this handles the flush command by doing nothing.\n",
    "        # you might want to specify some extra behavior here.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\n",
    "# model.fc = torch.nn.Linear(2048, n_classes)\n",
    "# model = torchvision.models.resnet34(pretrained=True)\n",
    "# model.fc = torch.nn.Linear(512, n_classes)\n",
    "\n",
    "\n",
    "#(last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
    "model = pretrainedmodels.se_resnext50_32x4d()\n",
    "model.avg_pool = torch.nn.AdaptiveAvgPool2d(output_size=1)\n",
    "model.last_linear = torch.nn.Linear(2048, n_classes)\n",
    "model_name = 'se_resnext50_32x4d'\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "plist = [{'params': model.parameters(), 'lr': 2e-5}]\n",
    "optimizer = optim.Adam(plist, lr=2e-5)\n",
    "\n",
    "# model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_model = None\n",
    "log = Logger()\n",
    "log.open(path.join(saved, 'log.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = f'{saved}/{model_name}_checkpoint.pth'\n",
    "fold = 0\n",
    "amp_ckpt_path = f'{saved}/{model_name}_fold{fold}_amp_checkpoint.pt'\n",
    "\n",
    "\n",
    "opt_level = 'O1'\n",
    "\n",
    "if path.exists(amp_ckpt_path):\n",
    "    print(f'===> load {amp_ckpt_path}')\n",
    "    checkpoint = torch.load(amp_ckpt_path)\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    amp.load_state_dict(checkpoint['amp'])\n",
    "    epoch_start = checkpoint['epoch']\n",
    "\n",
    "elif path.exists(ckpt_path):\n",
    "    print(f'===> load {ckpt_path}')\n",
    "    ckpt = torch.load(ckpt_path, map_location='cuda:0')\n",
    "    optimizer.load_state_dict(ckpt['optim']),\n",
    "    epoch_start = ckpt['epoch']\n",
    "    model.load_state_dict(ckpt['state'])\n",
    "    \n",
    "    # Initialization\n",
    "    \n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n",
    "    \n",
    "    log.write(f'resume from epoch {epoch_start}\\n')\n",
    "else:\n",
    "    epoch_start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen(p,t=0):\n",
    "    if t!=0:\n",
    "        return p**t\n",
    "    else:\n",
    "        return p\n",
    "\n",
    "def cls_do_eval(nets, batch_data, augment=[], t=0):\n",
    "    num_augment = 0\n",
    "    probability_label = None\n",
    "    for net in nets:\n",
    "        if 1: #  null\n",
    "            logit =  net(batch_data)  #net(input)\n",
    "            probability = torch.sigmoid(logit)\n",
    "            if probability_label is None:\n",
    "                probability_label = sharpen(probability,0)\n",
    "            else:\n",
    "                probability_label += sharpen(probability,0)\n",
    "            num_augment+=1\n",
    "\n",
    "        if 'flip_lr' in augment:\n",
    "            logit = net(torch.flip(batch_data,dims=[3]))\n",
    "            probability  = torch.sigmoid(logit)\n",
    "\n",
    "            probability_label += sharpen(probability, t)\n",
    "            num_augment+=1\n",
    "            \n",
    "        if 'flip_ud' in augment:\n",
    "            logit = net(torch.flip(batch_data,dims=[2]))\n",
    "            probability = torch.sigmoid(logit)\n",
    "\n",
    "            probability_label += sharpen(probability, t)\n",
    "            num_augment+=1\n",
    "        \n",
    "    probability_label = probability_label/num_augment\n",
    "    return probability_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = ['null', 'flip_lr','flip_ud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inference\n",
      " 1943 / 2245"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "\n",
    "print('\\nInference')\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_pred = np.zeros((len(test_dataset) * n_classes, 1))\n",
    "\n",
    "tbar = tqdm(data_loader_test)\n",
    "for i, x_batch in enumerate(tbar):\n",
    "#     print(f'\\r {i} / {len(data_loader_test)}', end='')\n",
    "    x_batch = x_batch[\"image\"]\n",
    "    x_batch = x_batch.to(device, dtype=torch.float)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "#         pred = model(x_batch)\n",
    "        pred = cls_do_eval([model], x_batch, augment)\n",
    "        test_pred[(i * val_batch_size * n_classes):((i + 1) * val_batch_size * n_classes)] = pred.detach().cpu().reshape((len(x_batch) * n_classes, 1))\n",
    "        \n",
    "#         test_pred[(i * batch_size * n_classes):((i + 1) * batch_size * n_classes)] = torch.sigmoid(\n",
    "#             pred).detach().cpu().reshape((len(x_batch) * n_classes, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "\n",
    "submission =  pd.read_csv(os.path.join(dir_csv, 'stage_1_sample_submission.csv'))\n",
    "submission = pd.concat([submission.drop(columns=['Label']), pd.DataFrame(test_pred)], axis=1)\n",
    "submission.columns = ['ID', 'Label']\n",
    "\n",
    "submission.to_csv(f'submission_{resize_size[0]}_fold{fold}.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID_28fbab7eb_epidural</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID_28fbab7eb_intraparenchymal</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID_28fbab7eb_intraventricular</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID_28fbab7eb_subarachnoid</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID_28fbab7eb_subdural</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>ID_28fbab7eb_any</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>ID_877923b8b_epidural</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ID_877923b8b_intraparenchymal</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>ID_877923b8b_intraventricular</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>ID_877923b8b_subarachnoid</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID  Label\n",
       "0          ID_28fbab7eb_epidural    0.5\n",
       "1  ID_28fbab7eb_intraparenchymal    0.5\n",
       "2  ID_28fbab7eb_intraventricular    0.5\n",
       "3      ID_28fbab7eb_subarachnoid    0.5\n",
       "4          ID_28fbab7eb_subdural    0.5\n",
       "5               ID_28fbab7eb_any    0.5\n",
       "6          ID_877923b8b_epidural    0.5\n",
       "7  ID_877923b8b_intraparenchymal    0.5\n",
       "8  ID_877923b8b_intraventricular    0.5\n",
       "9      ID_877923b8b_subarachnoid    0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission =  pd.read_csv(os.path.join(dir_csv, 'stage_1_sample_submission.csv'))\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID,Label\n",
      "ID_28fbab7eb_epidural,1.710653305053711e-05\n",
      "ID_28fbab7eb_intraparenchymal,0.00019550323486328125\n",
      "ID_28fbab7eb_intraventricular,0.0\n",
      "ID_28fbab7eb_subarachnoid,0.0005307197570800781\n",
      "ID_28fbab7eb_subdural,0.0011472702026367188\n",
      "ID_28fbab7eb_any,0.0027923583984375\n",
      "ID_877923b8b_epidural,8.344650268554688e-06\n",
      "ID_877923b8b_intraparenchymal,4.655122756958008e-05\n",
      "ID_877923b8b_intraventricular,0.0\n"
     ]
    }
   ],
   "source": [
    "# !head submission_224.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle competitions submit -f submission_224.csv -m from_gcp rsna-intracranial-hemorrhage-detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
